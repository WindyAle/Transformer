{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979f93f3",
   "metadata": {},
   "source": [
    "# 완성된 Transformer 모델\n",
    "```Plain Text\n",
    "Transformer/\n",
    "├── main.py               # main 파일 (테스트용)\n",
    "└── modules/\n",
    "    ├── MyTransformer.py  # 인코더-디코더\n",
    "    └── common.py         # 여러 번 재사용되는 구조들\n",
    "                          ## attention, Embedding, MultiHeadAttention, FeedForward\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05409c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, vocab_size, pad_token_id=0):\n",
    "        self.vocab_size = vocab_size        # 단어사전 크기\n",
    "        self.hidden_size = 768              # 은닉층 차원수 (attention_eads의 배수)\n",
    "        self.max_position_embeddings = 768  # 최대 시퀀스 길이\n",
    "        self.num_attention_heads = 12       # 어텐션 헤드 개수\n",
    "        self.num_hidden_layers = 12         # 레이어 개수\n",
    "        self.intermediate_size = 2048       # FeedForward 레이어의 중간 차원\n",
    "        self.hidden_dropout_prob = 0.1      # dropout 비율\n",
    "        self.layer_norm_eps = 1e-12         # epsilon\n",
    "        self.pad_token_id = pad_token_id    # 패딩 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6181226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소스와 타겟의 단어사전 크기가 다르다고 가정 (번역기 등)\n",
    "SOURCE_VOCAB_SIZE = 10000\n",
    "TARGET_VOCAB_SIZE = 15000\n",
    "\n",
    "PAD_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf773f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source IDs shape: torch.Size([2, 12])\n",
      "Target IDs shape: torch.Size([2, 10])\n",
      "Output Logits shape: torch.Size([2, 10, 15000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modules.MyTransformer import Transformer\n",
    "\n",
    "config_enc = Config(vocab_size=SOURCE_VOCAB_SIZE, pad_token_id=PAD_ID)\n",
    "config_dec = Config(vocab_size=TARGET_VOCAB_SIZE, pad_token_id=PAD_ID)\n",
    "\n",
    "model = Transformer(config_enc, config_dec)\n",
    "model.eval() # 평가 모드\n",
    "\n",
    "# 더미 입력 데이터\n",
    "# (batch_size=2, source_seq_len=12, target_seq_len=10)\n",
    "source_ids = torch.tensor([\n",
    "    [101, 2054, 2064, 2106, 102, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [101, 3000, 4000, 102, 2000, 102, 0, 0, 0, 0, 0, 0]\n",
    "], dtype=torch.long)\n",
    "\n",
    "target_ids = torch.tensor([\n",
    "    [201, 3054, 3064, 3106, 202, 0, 0, 0, 0, 0],\n",
    "    [201, 4000, 5000, 202, 6000, 202, 0, 0, 0, 0]\n",
    "], dtype=torch.long)\n",
    "\n",
    "print(f\"Source IDs shape: {source_ids.shape}\")\n",
    "print(f\"Target IDs shape: {target_ids.shape}\")\n",
    "\n",
    "# 모델이 내부적으로 모든 마스크를 생성하여 처리\n",
    "logits = model(source_ids, target_ids)\n",
    "print(f\"Output Logits shape: {logits.shape}\")\n",
    "\n",
    "# (batch_size, target_seq_len, target_vocab_size)\n",
    "# 예상 출력: [2, 10, 15000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
